{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "In6WYcKTNP3i"
      },
      "outputs": [],
      "source": [
        "!pip install gpytorch\n",
        "!pip install torcheval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nMKgRJFnI6_N"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import gpytorch\n",
        "from torcheval.metrics import R2Score\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUtSEYjEI7qv"
      },
      "outputs": [],
      "source": [
        "#чтение данных\n",
        "with open('path_to_csv', 'rb') as file:\n",
        "  df = pd.read_csv(file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#вычисление дополнительных спектральных индексов\n",
        "df['sr4_3_mean'] = df['B08_mean']/df['B04_mean']\n",
        "df['sr5_4_mean'] = df['B11_mean']/df['B08_mean']\n",
        "df['kt_1_mean'] = 0.3037 * df['B02_mean'] + 0.2793 * df['B03_mean'] + 0.4743 * df['B04_mean'] + 0.5585 * df['B08_mean'] + 0.5082 * df['B11_mean'] + 0.1863 * df['B12_mean']\n",
        "df['kt_2_mean'] = - 0.2941 * df['B02_mean'] - 0.243 * df['B03_mean'] - 0.5424 * df['B04_mean'] + 0.7276 * df['B08_mean'] + 0.0713 * df['B11_mean'] - 0.1608 * df['B12_mean']\n",
        "df['kt_3_mean'] = 0.1511 * df['B02_mean'] + 0.1973 * df['B03_mean'] + 0.3283 * df['B04_mean'] + 0.3407 * df['B08_mean'] - 0.7117 * df['B11_mean'] - 0.4559 * df['B12_mean']"
      ],
      "metadata": {
        "id": "bRq1MKBCVruF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#вычисление усредненных географичеких координат выделов\n",
        "def avg_long(polygon):\n",
        "  my_string = polygon\n",
        "  my_string = re.sub(r'[A-Za-z()]', '', my_string)\n",
        "  mean_longitude = 0\n",
        "  с = 0\n",
        "  for i in range(len(my_string.split(','))):\n",
        "    mean_longitude += float(my_string.split(',')[i].split(' ')[1])\n",
        "    c = i + 1\n",
        "  mean_longitude = mean_longitude / c\n",
        "  return mean_longitude\n",
        "\n",
        "def avg_lat(polygon):\n",
        "  my_string = polygon\n",
        "  my_string = re.sub(r'[A-Za-z()]', '', my_string)\n",
        "  mean_latitude = 0\n",
        "  с = 0\n",
        "  for i in range(len(my_string.split(','))):\n",
        "    mean_latitude += float(my_string.split(',')[i].split(' ')[2])\n",
        "    c = i + 1\n",
        "  mean_latitude = mean_latitude / c\n",
        "  return mean_latitude\n",
        "\n",
        "df['mean_latitude'] = df['geometry'].apply(avg_lat)\n",
        "df['mean_longitude'] = df['geometry'].apply(avg_long)"
      ],
      "metadata": {
        "id": "Gy3WrNRjA2L7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLzVIbZ8LVXg"
      },
      "outputs": [],
      "source": [
        "#выделение целевых значений\n",
        "target_1 = df['height']\n",
        "target_2 = df['timber_stock']\n",
        "target_3 = df['basal_area']\n",
        "df.drop(['date', 'height', 'timber_stock', 'basal_area', 'geometry'], axis= 1, inplace=True)\n",
        "#масштабирование данных\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(df)\n",
        "data = scaler.transform(df)\n",
        "\n",
        "data = df.to_numpy()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "x_data = torch.tensor(data, dtype=torch.float32).to(device)\n",
        "\n",
        "y_data = torch.stack([\n",
        "    torch.tensor(target_1.to_numpy(), dtype=torch.float32),\n",
        "    torch.tensor(target_2.to_numpy(), dtype=torch.float32),\n",
        "    torch.tensor(target_3.to_numpy(), dtype=torch.float32),\n",
        "], -1).to(device)\n",
        "#разделение на тренировочную и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#модель Multi-Task Gaussian Process Regression\n",
        "class MultitaskGPModel(gpytorch.models.ExactGP):\n",
        "    def __init__(self, train_x, train_y, likelihood):\n",
        "        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n",
        "        self.mean_module = gpytorch.means.MultitaskMean(\n",
        "            gpytorch.means.ConstantMean(), num_tasks=3\n",
        "        )\n",
        "        self.covar_module = gpytorch.kernels.MultitaskKernel(\n",
        "            gpytorch.kernels.RBFKernel(), num_tasks=3, rank=2\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean_x = self.mean_module(x)\n",
        "        covar_x = self.covar_module(x)\n",
        "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)\n",
        "\n",
        "\n",
        "likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=3)\n",
        "model = MultitaskGPModel(X_train, y_train, likelihood)"
      ],
      "metadata": {
        "id": "FWtgkNm7BHM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "smoke_test = ('CI' in os.environ)\n",
        "training_iterations = 2 if smoke_test else 100\n",
        "\n",
        "#поиск оптимальных гиперпараметров модели\n",
        "model.train().to(device)\n",
        "likelihood.train()\n",
        "history = []\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
        "\n",
        "#loss для GPs - предельное логарифмическое правдоподобие\n",
        "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
        "\n",
        "for i in range(training_iterations):\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X_train)\n",
        "    loss = -mll(output, y_train)\n",
        "    loss.backward()\n",
        "    print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\n",
        "    optimizer.step()\n",
        "    history.append(loss.item())"
      ],
      "metadata": {
        "id": "dhCwGOQPBL89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#график обучения\n",
        "plt.plot(history)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('the marginal log likelihood (loss)')\n",
        "plt.title('Training MTGPR')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q2HNJ8hCBXIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "likelihood.eval()\n",
        "\n",
        "#предсказания модели\n",
        "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
        "    predictions = likelihood(model(X_test))\n",
        "    mean = predictions.mean\n",
        "    lower, upper = predictions.confidence_region()"
      ],
      "metadata": {
        "id": "25vw49mMBcAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#подсчет метрик результатов\n",
        "metric_1 = R2Score().update(mean[:, 0], y_test[:, 0])\n",
        "r_sq_1 = metric_1.compute()\n",
        "mse_1 = torch.nn.MSELoss()(mean[:, 0], y_test[:, 0])\n",
        "metric_2 = R2Score().update(mean[:, 1], y_test[:, 1])\n",
        "r_sq_2 = metric_2.compute()\n",
        "mse_2 = torch.nn.MSELoss()(mean[:, 1], y_test[:, 1])\n",
        "metric_3 = R2Score().update(mean[:, 2], y_test[:, 2])\n",
        "r_sq_3 = metric_3.compute()\n",
        "mse_3 = torch.nn.MSELoss()(mean[:, 2], y_test[:, 2])\n",
        "print(f\"coefficient of determination (height): {r_sq_1}\")\n",
        "print(\"MSE (height): {}\".format(mse_1))\n",
        "print(f\"coefficient of determination (timber_stock): {r_sq_2}\")\n",
        "print(\"MSE (timber_stock): {}\".format(mse_2))\n",
        "print(f\"coefficient of determination (basal_area): {r_sq_3}\")\n",
        "print(\"MSE (basal_area): {}\".format(mse_3))"
      ],
      "metadata": {
        "id": "5ZCLG_bCBk1Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "13-J5SVAJRDHX6Byl8YNDsIAO05jNkcrC",
      "authorship_tag": "ABX9TyOP5CRndiTLNip7LeZS0spq"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}